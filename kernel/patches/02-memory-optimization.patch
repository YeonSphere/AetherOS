diff --git a/mm/memory.c b/mm/memory.c
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -1,5 +1,8 @@
 // AetherOS Memory Optimizations
 
+#define AETHER_MEMORY_COMPACT_THRESHOLD 80  // Compact at 80% usage
+#define AETHER_THP_DEFRAG_THRESHOLD 60     // Defrag for THP at 60% fragmentation
+
 // Enhanced memory compaction
 static unsigned long aether_compact_zone(struct zone *zone)
 {
     unsigned long nr_reclaimed;
     unsigned long nr_scanned;
+    int fragmentation_index;
+    
+    // Check if compaction is needed
+    fragmentation_index = fragmentation_index_zone(zone);
+    if (fragmentation_index < AETHER_MEMORY_COMPACT_THRESHOLD)
+        return 0;
     
     // Aggressive compaction for high memory pressure
     compact_zone(zone, NULL);
     
     // Defragment for huge pages if needed
-    if (transparent_hugepage_enabled(zone->zone_pgdat))
+    if (transparent_hugepage_enabled(zone->zone_pgdat) &&
+        fragmentation_index > AETHER_THP_DEFRAG_THRESHOLD)
         compact_zone_hugepages(zone, NULL);
     
     return nr_reclaimed;
 }
 
 // Optimized page allocation
 static struct page *aether_alloc_pages(gfp_t gfp_mask, unsigned int order)
 {
     struct page *page;
     int nid = numa_node_id();
+    int alloc_flags = ALLOC_WMARK_LOW;
     
-    // Try local node first
-    page = __alloc_pages_node(nid, gfp_mask, order);
-    if (page)
-        return page;
+    // Fast path for order-0 allocations
+    if (!order && (gfp_mask & __GFP_ATOMIC)) {
+        page = __alloc_pages_node(nid, gfp_mask, 0);
+        if (page)
+            return page;
+    }
     
-    // Try other nodes if local fails
-    return __alloc_pages(gfp_mask, order, nid, NULL);
+    // Use node-local allocation with fallback
+    if (gfp_mask & __GFP_THISNODE)
+        alloc_flags |= ALLOC_HARDER;
+        
+    return __alloc_pages_nodemask(gfp_mask, order, nid, NULL);
 }
 
 // Enhanced page cache management
 static void aether_shrink_page_cache(struct zone *zone)
 {
     unsigned long nr_reclaimed;
+    unsigned long nr_to_reclaim;
+    int priority = DEF_PRIORITY;
     
-    // More aggressive reclaim under memory pressure
-    if (zone_watermark_ok(zone, 0, 0, 0, 0))
+    // Check if reclaim is needed
+    if (zone_watermark_ok(zone, 0, 0, 0, 0) &&
+        !zone_reclaimable(zone))
         return;
     
-    nr_reclaimed = shrink_all_memory(SHRINK_MEMORY);
+    // Calculate how much to reclaim
+    nr_to_reclaim = zone_page_state(zone, NR_FILE_PAGES) >> 2;
+    
+    // Aggressive reclaim for high pressure
+    if (zone_watermark_ok(zone, 0, 0, 0, 0))
+        priority -= 2;
+        
+    nr_reclaimed = shrink_zone(zone, NULL, nr_to_reclaim, priority);
     
     if (nr_reclaimed < nr_to_reclaim)
         wake_all_kswapd();
-}
